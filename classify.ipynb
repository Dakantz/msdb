{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bit1993a28ad5904dc18799eec7f411270a",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as tfl\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import json\n",
    "import os, time\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.0'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = tfds.features.text.Tokenizer(alphanum_only=False)\n",
    "vocabulary_set = set()\n",
    "all_genres=set()\n",
    "max_entries=float(\"inf\")\n",
    "entries=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "error on file:  <_io.TextIOWrapper name='./data/test.json' mode='r' encoding='utf-8-sig'>\n"
    }
   ],
   "source": [
    "genres_list=[]\n",
    "scripts=[]\n",
    "for r, d, f in os.walk(\"./data\"):\n",
    "    for file in f:\n",
    "        if '.json' in file:  # only load 10 jsons for now\n",
    "\n",
    "            with open(os.path.join(r, file), mode='r', encoding='utf-8-sig') as prep_file:\n",
    "                try:\n",
    "                    script_data = json.load(prep_file)\n",
    "                    genres=script_data[\"genres\"] if script_data[\"genres\"] else []\n",
    "                    if None in genres:\n",
    "                        genres.remove(None)\n",
    "                    all_genres.update(genres)\n",
    "                    n=0\n",
    "                    script_tokenized=tokenizer.tokenize(script_data[\"script\"])\n",
    "                    vocabulary_set.update(script_tokenized)\n",
    "                    genres_list.append(genres)\n",
    "                    scripts.append(script_tokenized)\n",
    "                    entries+=1\n",
    "                    if entries>max_entries:\n",
    "                        break\n",
    "                    n+=1\n",
    "\n",
    "                    if entries>max_entries:\n",
    "                        break\n",
    "                except:\n",
    "                    print(\"error on file: \",prep_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_encoded=[]\n",
    "site_text_encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "for script in scripts:\n",
    "    script_joined=\" \".join(script)\n",
    "\n",
    "    scripts_encoded.append(site_text_encoder.encode(script_joined))\n",
    "\n",
    "scripts_padded = tf.keras.preprocessing.sequence.pad_sequences(scripts_encoded,\n",
    "                                                                padding='post',maxlen=site_words)\n",
    "all_genres_list=list(all_genres)\n",
    "genres_map=[]\n",
    "for genres in genres_list:\n",
    "    active_cats=[1 if genre in genres else 0 for genre in all_genres_list ]\n",
    "    genres_map.append(np.array(active_cats))\n",
    "scripts_stacked = tf.stack(scripts_padded)\n",
    "genres_stacked = tf.stack(genres_map)\n",
    "sites_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (scripts_stacked,genres_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_stacked.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "noise_dim = 100\n",
    "# Batch and shuffle the data\n",
    "train_dataset = sites_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocabulary_set)\n",
    "genres_size=genres_stacked.shape[1]\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 128\n",
    "def make_classifier():\n",
    "    model = tf.keras.Sequential([\n",
    "        tfl.Embedding(vocab_size, embedding_dim, input_shape=(None,)),\n",
    "        tfl.GRU(rnn_units),\n",
    "        tfl.Dense(genres_size*16),\n",
    "        tfl.Dense(genres_size,activation=\"elu\")\n",
    "    ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, None, 256)         72981504  \n_________________________________________________________________\ngru_6 (GRU)                  (None, 128)               148224    \n_________________________________________________________________\ndense_13 (Dense)             (None, 416)               53664     \n_________________________________________________________________\ndense_14 (Dense)             (None, 26)                10842     \n=================================================================\nTotal params: 73,194,234\nTrainable params: 73,194,234\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model=make_classifier()\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"mse\",\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train for 36 steps\nEpoch 1/3\n36/36 [==============================] - 33s 912ms/step - loss: 0.3874 - mse: 0.1237 - mae: 0.2631\nEpoch 2/3\n36/36 [==============================] - 32s 886ms/step - loss: 0.2414 - mse: 0.0740 - mae: 0.1465\nEpoch 3/3\n36/36 [==============================] - 32s 885ms/step - loss: 0.2341 - mse: 0.0726 - mae: 0.1447\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7ef86ff35bd0>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0.7425241  0.7471364  0.30532533 0.01257539 0.01210212 0.56437695\n  0.08027765 0.00756055 0.00885526 0.00907336 0.06766494 0.05849902\n  0.07031178 0.37965572 0.20553645 0.01796708 0.00775568 0.4442241\n  0.01784999 1.         0.4018589  0.40778035 0.43002096 0.06461545\n  0.01046722 0.01085936]] (1, 26)\nMovie in Action\nMovie in Thriller\nMovie in Comedy\nMovie in Drama\nwanted: ['Action', 'Adventure', 'Sci-Fi']\n"
    }
   ],
   "source": [
    "#test index\n",
    "index=19\n",
    "test_script=scripts[index]\n",
    "test_encoded=site_text_encoder.encode(\"\".join(test_script))\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences([test_encoded],\n",
    "                                                                padding='post',maxlen=site_words)\n",
    "predictions=model(test_padded).numpy()\n",
    "predictions=predictions/predictions.max()\n",
    "print(predictions,predictions.shape)\n",
    "for i,genre in enumerate(all_genres_list):\n",
    "    if predictions[0,i] > 0.5:\n",
    "        print(\"Movie in\", genre)\n",
    "print(\"wanted:\",genres_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}